# Задача 3
## Партнер: ТЕХНОНИКОЛЬ
### Контекст: 
в компании активно внедряются инициативы по улучшению рабочих процессов. Для удобства сотрудников разработан специальный цифровой инструмент — «Активный сотрудник», который значительно облегчает процесс подачи идей. Ежегодно через эту систему поступает порядка 30 000 предложений, однако среди них встречаются повторяющиеся идеи. Чтобы повысить эффективность обработки, важно внедрить механизмы обнаружения дублей. Это позволит показывать схожие предложения непосредственно при их внесении, а также облегчит работу модераторам, предоставляя возможность объединения похожих инициатив в группы
### Задача: 
необходимо разработать алгоритм для поиска (выявления) дублей предложений по улучшениям внутри компании.

### Описание от представителя компании:
Мини-приложение, выложенное на платформе «Активный сотрудник Технониколь».
Это приложение создано для того, чтобы каждый сотрудник компании, каждый из девяти тысяч мог внести свое предложение по улучшению, по улучшению охраны труда, по улучшению каких-то процессов, по созданию каких-то новых цифровых продуктов и так далее. То есть спектр этих предложений может быть очень большой.
Это приложение пользуется большой популярностью. В год вносится более 30 тысяч предложений в это приложение и регулярно внедряется. Целая команда работает, которая занимается внедрением этих предложений, улучшением этих процессов, что позволяет улучшать и увеличивать производительность труда компании в целом за счет этого.
И, собственно, есть набор проблематик, который соображает этот продукт - это __дубли__. 
Так как сотрудник не видит, не может физически просмотреть вот эти 30 тысяч предложений там, или какие предложения были поданы ранее, ему сложно понять, дублируются ли его предложения с каким-либо еще.
И по итогу у нас получается то, что есть набор дублей, то есть дублирующих предложений, которые поданы разными сотрудниками, которые необходимо выявлять. Выявлять, как на стадии подачи предложения, то есть посвечивать сотруднику то, что такое предложение уже есть, от такого-то сотрудника тогда-то было подано и там будет реализовано тогда-то.
Вот, а также для наших агентов перемен, это те, кто рассматривает предложение, подсвечивает тоже то, что такое предложение уже подавалось или подобное предложение уже подавалось, не хотите ли его там собрать в группу, либо отклонить на основании того, что это дубль.
В чем сложность решения данной задачи? То, что люди формулируют предложение по-разному. И каких-то супер отличительных признаков то, что это дубль, особо нет. Скорее надо основываться на том предложении, которым подал и, собственно, на основании сравнения, может быть, выяснять дублит или нет, по крайней мере, с какой-то вероятностью.
То есть, если это с высокой вероятностью, то, что эти два предложения похожи друг на дружку, выводить, показывать агенту перемен и сотруднику. Обратите внимание, примите решение, дублит или нет. Подробная информация по кейсу описана в документе док, там коллеги, я так понимаю, пришлют после нашей встречи.
Там больше деталей. Так или иначе, мы предоставим набор данных, на которых можно будет проверять работу алгоритма. Ряд тысяч предложений мы можем прислать, по которым можно будет проверить работу алгоритма.
При этом, заведомо, мы можем добавить туда дубли, для того чтобы смотреть, поняла ли система или нет. 

То есть будет порядка нескольких тысяч предложений, разбитых по определенным колонкам, они как-то в базе хранятся определенным образом. И изучив вот эти колонки, мы должны понять, где есть потенциальные паттерны дублей и поразработать алгоритм, который их выявляет.
Но, со всей очевидностью, здесь, скорее всего, самый очевидный и простой путь — это задействовать LLM-ки. 

Готовы к любому решению, то есть если оно будет на базе с использованием моделей, нам подходит. Мы в целом в этом направлении тоже движемся. Единственное, что интересно будет посмотреть, каким способом вы их решите. То есть в целом для нас это не является блокером, мы как раз наоборот в эту сторону смотрим, в сторону использования языковых моделей у себя.

Размеченный дубль, недубль пока таблицы нет. Но мы можем при подготовке данных это сделать. То есть, ну, понятно, что ограниченное количество, а пометить то, что это дубли, и тогда можно будет на это основываться. То есть, у нас есть большой, ну, касательно, ну, вообще, самих предложений, там, порядка, ну, ста тысяч, наверное.
Ну, какой-то набор данных можем подготовить размеченным.

На двух этапах должны определяться дубли. Первый это в тот момент, когда сотрудник сам вводит, и в тот момент, когда уже заявка обработана и поступает в базу, и уже это как рекомендация для эксперта, который будет принять это предложение. 

## **1 Цели и предпосылки**
### **1.1 Обоснованность разработки продукта**
### **Бизнес цель**
Бизнес цель – замена ручной работы прогнозами модели, которые будут использоваться для:
- поиска дублей предложений
- рекомендации по актуальным предложениям

### **Описание текущего бизнес-процесса**


### **Польза от внедрения ML модели**
Внедрение ML модели сократит временные затраты на оценку предложений, исключат ручной перебор, увеличит точность определения значимых предложений, которые необходимо брать в работу в первую очередь

### **Критерии успеха:**
- модель выдаёт прогнозы с ≥ точностью не ниже 80%

### **1.2 Бизнес требования и ограничения**
**Целевое видение**

- Необходимо делать предсказания предложений на 6 следующих месяцев. Прогнозы получать 2 раза в год до последнего числа месяца: 
  - Апрель
  - Ноябрь

**Бизнес-требования и ограничения для пилота**

- Необходимо cделать предсказания предложений на 6 следующих месяцев до конца мая.
- Гранулярность расчёта – отдельный запрос
- Предсказываются запросы отдельно для 3-х категорий. 
- Прогнозы делаются для всех подразделений 

**Проведение пилота**

- Тестирование модели и оценка пилота будут проводится на вводимых данных в поисковую строку
  Плюс использования чековых данных:
  - Быстрая оценка пилота – имеющиеся данные 
  - Как следствие, увеличение времени для ролл-аута и доработок модели

Недостатки:

- Увеличение стоимости проекта
- Риск усложнения проекта

**Критерии успешности пилота**


### 1.3 Что входит в скоуп итерации, а что нет
- Нет интеграции во внутренние системы
- Нет визуализации результатов в дэшборде
### 1.4 Предпосылки решения
Планируется MVP, возможно с ансамблем моделей.

Младшие разработчики не только должны участвовать в процессе, но и понимать всю методологию. Все члены команды должны иметь схожие знания и способность развивать/поддерживать продукт самостоятельно.

- Проект ведётся в Githab
- Документация – readme_doc.md. Должна содержать описание алгоритма, результаты промежуточных тестов
- Код. В JupyterLab, соответствует PEP8, разбит на модули
- Стек: PyTorch, Catboost + стандартный для DS, tf-idf, DistilBERT, word2vec,cbow
- БД: redis/sqlite/postgresql

## **2 Методология**
### **2.1 Постановка задачи**
Создание прогнозной модели, задача регрессии.
### **2.2 Блок-схема (в приложении)**
### **2.3  Этапы решения задачи**
### **2.3.0 Этап 0 – Подготовка данных**


**2.3.1 Этап 1 – Проверка данных**

Общие требования к данным:

- Данные запросов сотрудников (110к), процент пропусков < 5% (??)
- Присутствие дубликатов запросов


**Риски:**


### **2.3.2 Этап 2** 
**Baseline**

Бэйзлайн – прогнозы торговых представителей по каждому магазину. Это главный ориентир при сравнении всех моделей. Простое прогнозирование – скользящие окна по предыдущим продажам, кластеризация магазинов, логистическая регрессия если рассматривать задачу как классификационную (определять принадлежность к классу, минуя этап прогноза продаж), либо не дают минимально значимых результатов, либо требуют обработку и подбор признаков, что схоже по трудозатратам с построением MVP.

Основной таргет – продажи категории товара в магазине за месяц (одно значение на все следующие 6 месяцев).

Дополнительный таргет – определение диапазона продаж, которые используются для дальнейшей сегментации. Диапазон продаж:

- малый магазин, выручка < 20 т.р.
- средний, от 20 т.р. до 80 т.р.
- большой, > 80 т.р.

Метрики вычисляются на данном этапе, после сбора данных. Риски этапа: 

- Отсутствие данных по точным значениям при наличии только диапазонов. Будет использоваться только метрика классификации для оценки бэйслайна, MVP сравниваться с самими собой.
- Некорректный выбор метрики из-за дисбаланса класса. Последует замена метрики на более корректную.

Основная метрика – MAPE. В прошлом равнялась 65% (?).

Дополнительная метрика – Accuracy, верное предсказание типа запроса. Она не будет использоваться в расчётах, скорее для презентации бизнесу, насколько точно определялись сегменты запросов из прогнозов. В прошлом она равнялась 87% (?).
### **MVP, Общие положения**
Общий размер выборки – /строк.

Для валидации отбираются 25% точек, стратифицируя их по типу. Для обучения используются средние продажи категории за период (год), усредняя месячные продажи.

Гранулярность: отдельно взятый магазин, таргет – как в бэйзлайне.


Метрика – MAPE, R2. 

Использование R2 необходимо для:

- понимания, насколько хорошо модель связывает выбранные признаки с целевой переменной. Как одно из следствий – доказательство бизнесу преимущества использования модели перед бейзлайном
- экономии бюджета - определение необходимого набора признаков при их закупке/сборе

Необходимый результат этапа:

- Обучение модели с заданной точностью
- Получение набора признаков для отдельного MVP

**Общие для MVP задачи этапа**

- Отбор признаков для модели. Для catboost – оценка важности признаков встроенным методом feature\_importance, для физической модели – L1 регуляризация
- Достижение MAPE > 80%
### **MVP 1, Построение модели оценки спроса**
Алгоритм решения – математическая (физическая) модель спроса в магазине. Компоненты модели – взвешенные трафики потребителей в магазин в радиусе 20 метрах, вызванные определённой причиной. Данные парсятся с яндекс.карт и 2GIS, измеряются в человеках в час. Пример:

- пешеходный трафик рядом с магазином
- автомобильный трафик
- трафик от новостроек
- трафик в бизнес-центры
- университеты и т. д. 

Риски:

- Слишком высокая региональная специфика, как следствие, обучение моделей для отдельного региона. Можно произвести кластеризацию регионов, получив кластеры-макрорегионы, чтобы снизить количество моделей. Или увеличить вклад региональности в общую модель
- Дороговизна набора признаков. Будет использовано слишком много закупаемых данных. Риск можно снизить путём увеличения отдачи от проекта (распространение его не только на магазины, но и на других клиентов – бары, рестораны и т.д.). Или отказ от закупки данных, переход к самостоятельному сбору трафиков.


### **2.3.3 Этап 3 – Интерпретация моделей**
Результат этапа:

- Оценка влияния различных факторов, сравнение их с бизнес-логикой
- Проверка отсутствия переобучения моделей

Методы оценки:

- Для модели оценки спроса – оценка весов для каждого запроса
- Модели прогноза продаж – изучение разбиения решающего дерева и весов факторов

При наличии дисбаланса в значимости факторов будет произведено переобучение моделей и/или дополнительный feature engineering.

Главные риски этапа: несогласуемость её с бизнес-логикой. В этом случае происходит возврат к этапу 2.3.2
### **2.3.4 Этап 4 – Ансамблирование**
Результат этапа:

- Выбор ансамбля (предположительно, сумма от взвешенных ответов двух моделей)
- Получение ансамбля с точностью большей, чем у отдельно взятых моделей
- Возврат к этапу 2.3.1 или отказ от ансамблирования при плохих метриках, выбор наиболее точной модели
### **2.3.5 Этап 5 – Анализ ансамблиевой модели**
Интерпретация результатов ансамблиевой модели. Поиск взаимосвязей между признаками для двух отдельных моделей.

Показ бизнес-заказчику предварительных результатов. Главный риск - неудовлетворённость заказчика точностью или наглядностью, понятностью результатов. Возврат к этапу 2.3.1
### **2.3.6 Этап 6 – Интеграция бизнес-правил**
Интеграция бизнес-правил заключается ... 
Возможна выработка новых стратегий по взаимодействию с классами или получение новых классов на основе прогнозов – ...

### **2.3.7 Этап 7 – Подготовка к пилоту**
Итоговый формат передачи данных в формате Excel, либо дашборд на странице с результатами, либо уведомление в телеграм-бот

## **3 Пилот**
### **3.0 Описание методики пилота**
Для 3-х пилотных запросов делаются прогнозы предложений. 
По введеннымтзапросам делаются предсказания уже имеющихся за полгода и сообщение о дублировании – тестовые значения, на основании которых считаются метрики точности.

На данном этапе развития проекта A/B тест не производится, т.к. отдача от проекта должна быть столь значительна, что статистически подтверждать гипотезы не должно иметь смысла. 
### **3.1 Оценка успешности пилота**
Общие с критериями успешности проекта.
## **4 Внедрение в production**
На данной итерации не требуется, достаточно рассчитанных значений